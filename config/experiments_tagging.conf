# Main configuration. Do not edit! Copy to experiments.conf and change that.

word_emb {
  path = ./conll-2012/百度百科字嵌入
  size = 300
}

best {
  # Edit this
  data_dir = ./conll-2012/ontoNote5.0
  
  # Computation limits.
  max_top_antecedents = 30
  ffnn_size = 2000
  
  max_training_sentences = 5
  top_span_ratio = 0.4
  max_num_speakers = 20
  max_segment_len = 128

  # Learning
  bert_learning_rate = 1e-5
  task_learning_rate = 2e-4
  num_docs = 1000

  # Model hyperparameters.
  char_vocab = ./conll-2012/char.vocab
  word_emb_path = ${word_emb}
  dropout_rate = 0.3
  ffnn_depth = 1
  num_epochs = 26
  feature_size = 20
  max_span_width = 30
  use_metadata = true
  use_pos = false
  use_features = true
  use_segment_distance = true
  model_heads = true
  coref_depth = 2
  coarse_to_fine = true
  fine_grained = true
  use_prior = true

  # Other.
  single_example = true
  genres = ["bc", "bn", "mz", "nw", "pt", "tc", "wb"]
  eval_frequency = 1000
  report_frequency = 50
  log_root = ./bert
  adam_eps = 1e-6
  task_optimizer = adam
}

bert_base = ${best}{
  model_type = independent
  num_docs = 1810
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128
  
  # 每次修改bert_model与savepath
  bert_model = chinese_wwm_ext_L-12_H-768_A-12
  save_path = ./result_of_coref/ontoNote_CHN0.2
  train_path = ${best.data_dir}/train-bert-wwm-ext.chinese.128.jsonlines
  eval_path = ${best.data_dir}/dev-bert-wwm-ext.chinese.128.jsonlines
  test_path = ${best.data_dir}/test-bert-wwm-ext.chinese.128.jsonlines
  conll_eval_path = ${best.data_dir}/test.chinese.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = ${best.log_root}/${bert_base.bert_model}/bert_config.json
  vocab_file = ${best.log_root}/${bert_base.bert_model}/vocab.txt
  tf_checkpoint = ${best.log_root}/${bert_base.bert_model}/bert_model.ckpt
  init_checkpoint = ${best.log_root}/${bert_base.bert_model}/bert_model.ckpt
}

emb_base = ${best}{
  model_type = independent
  num_docs = 1810
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128
  
  # 每次修改bert_model与savepath
  bert_model = chinese_wwm_ext_L-12_H-768_A-12
  save_path = ./result_of_coref/ontoNote_CHN16
  train_path = ${best.data_dir}/train-word2vec.chinese.128.jsonlines
  eval_path = ${best.data_dir}/dev-word2vec.chinese.128.jsonlines
  test_path = ${best.data_dir}/test-word2vec.chinese.128.jsonlines
  conll_eval_path = ${best.data_dir}/test.chinese.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = ${best.log_root}/${bert_base.bert_model}/bert_config.json
  vocab_file = ${best.log_root}/${bert_base.bert_model}/vocab.txt
  tf_checkpoint = ${best.log_root}/${bert_base.bert_model}/bert_model.ckpt
  init_checkpoint = ${best.log_root}/${bert_base.bert_model}/bert_model.ckpt
}

train_bert_base = ${bert_base}{
  tf_checkpoint = ${best.log_root}/cased_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = ${best.log_root}/cased_L-12_H-768_A-12/bert_model.ckpt
}

robert = ${best}{
  model_type = independent
  num_docs = 1810
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128

  #每次修改save_path
  save_path = ./result_of_coref/ontoNote_CHN6
  train_path = ${best.data_dir}/train-roberta.chinese.128.jsonlines
  eval_path = ${best.data_dir}/dev-roberta.chinese.128.jsonlines
  test_path = ${best.data_dir}/test-roberta.chinese.128.jsonlines
  conll_eval_path = ${best.data_dir}/test.chinese.v4_gold_conll
  max_training_sentences = 11
  bert_config_file = ${best.log_root}/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_config.json
  vocab_file = ${best.log_root}/chinese_roberta_wwm_ext_L-12_H-768_A-12/vocab.txt
  tf_checkpoint = ${best.log_root}/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_model.ckpt
  init_checkpoint = ${best.log_root}/chinese_roberta_wwm_ext_L-12_H-768_A-12/bert_model.ckpt
}

xlnet = ${best}{
  model_type = independent-xlnet
  num_docs = 1810
  xlnet_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 128
  # 每次修改save_path
  save_path = ./result_of_coref/ontoNote_XLN1
  train_path = ${best.data_dir}/train-xlnet.chinese.128.jsonlines
  eval_path = ${best.data_dir}/dev-xlnet.chinese.128.jsonlines
  test_path = ${best.data_dir}/test-xlnet.chinese.128.jsonlines
  conll_eval_path = ${best.data_dir}/dev.chinese.v4_gold_conll
  max_training_sentences = 11
  xlnet_config_file = ./xlnet/XLNet-base/xlnet_config.json
  vocab_file = ./xlnet/XLNet-base/spiece.model
  tf_checkpoint = ./xlnet/XLNet-base/xlnet_model.ckpt
  init_checkpoint = ./xlnet/XLNet-base/xlnet_model.ckpt

  use_tpu = False
  dropout = 0.1
  dropatt = 0.1
  clamp_len = -1
  use_bfloat16 = False
  init = normal
  init_std = 0.02
  init_range = 0.1
}

bert_large = ${best}{
  num_docs = 2802
  bert_learning_rate = 1e-05
  task_learning_rate = 0.0002
  max_segment_len = 384
  ffnn_size = 3000
  train_path = ${best.data_dir}/train.english.384.jsonlines
  eval_path = ${best.data_dir}/dev.english.384.jsonlines
  conll_eval_path = ${best.data_dir}/dev.english.v4_gold_conll
  max_training_sentences = 3
  bert_config_file = ${best.log_root}/bert_large/bert_config.json
  vocab_file = ${best.log_root}/bert_large/vocab.txt
  tf_checkpoint = ${best.log_root}/bert_large/bert_model.ckpt
  init_checkpoint = ${best.log_root}/bert_large/bert_model.ckpt
}
